---
title: "CH3 Scroing_appli"
author: "Youming"
date: "2023-09-21"
header-includes:
  - \usepackage{ctex}
  - \usepackage{geometry}
output: 
  pdf_document:
    latex_engine: xelatex
---

# CH3 Evamuation d'un score 

## 1. Context et objectif

$x1,x2 ...x_n, \in X$ sont des abservation répartie en Group $y_I \in \{1 L..G\}$ indique le groupe auquel appartient $n_i$  


## 2. Eurreur de classement 

* Le score s est de bonne qualité si la classe $\hat y(x)$ à la quelle il affecte x correspond, en moyenne, à la vraie classe y de x. , autrement dire : S est un bon score si on moyenne le classe estimée de x : $\hat y(x) \text{coinside avec } y$ 若$\hat y$与实际$y$符合，则s质量好

* Or, si l’on ne sait rien du modèle qui a généré (x,y), l’erreur de classement : $E(x,y)(1_{\{\hat y(x)=y\}})$ ne peut pas être déterminée. Il existe cependant plusieurs façons de l’estimer et d’évaluer ainsi la qualité de s.不过，若不知道生成(x,y)的模型，eurreur de classement \textbf{autrement dire : on souhaite que l'erreur de classement soit minimale. } 就不能被定论, 好在有以下方法可以评估s
$\varepsilon = E[1 \hat y(x) ≠ y)]$

Deux problèmes :

i) On ne connait pas la loi du couple $(x,y)$ ; on ne peut pas calculer $\varepsilon$  

ii) quand on a vrais loi du couple $(x,y)$, $\varepsilon$ dépend du classefier à traces $\hat y (x)$ et on ne peut pas la rendre arbitrairment proche de 0

![Erreur sera enorme](/Users/youmingma/Desktop/M2段乐瑶笔记/风险探测coring_applique_detection_risque/my_cours/Doc/2.jpeg)

Pour(ii) , il n'y a rien à faire, pour (i) on dispose plusieurs de méthode d'estimation


### Eurreur théorique

En analyse dicriminante probabiliste, on modélise les donées du groupe g par $f_g(•, \theta_g)$ et le poids du groupe est $\pi_g$. L'erreur théorique est alors : 
$$\hat \epsilon_{th} = \sum^G_{g=1} \hat \pi_g \int_{\{\infty\in X; \hat y (\infty) \neq g\}}f_g(x, \hat \theta_g)dx$$
Justification : Voir CH2

L'estimateur $\hat \varepsilon$ possède deux inconvénients : 

概率建模：在概率判别分析中，我们试图使用条件概率密度函数$f_g(•,\theta_g)$，对属于不同组（通常表示为 G）的数据进行建模。每个组都有一个权重 $\pi_g$，代表属于该组的数据比例。

(a) il hérite du biais du modèle postulé 

(b) il est fréquent que les finctions $f_g$ ne permettent pas de calculer $\hat \varepsilon_{th}$ explicitement \footnote{méthode Monte Carlo,随机抽样统计方法}

\color{darkgray}

理论误差：理论误差 $\hat \epsilon_{th}$ 是理论分类误差的度量。它被定义为每个组 g 的分类误差之和。总和的每个项都对应于密度函数 $f_g(x, \hat \theta_g)$ 在数据集上的积分，在数据集上，模型错误地分配了相关的组 g，即 $\hat y (\infty) \neq g$。
$\hat \varepsilon$ 估计器的缺点：

(a) 假设模型的偏差：$\hat \epsilon_{th}$估计器有一个主要缺点。\textbf{它继承了假定模型的偏差}，这意味着如果用于估计 $f_g$ 密度的基本概率模型有偏差或不正确，那么 $\hat \epsilon_{th}$ 也会有偏差，无法准确评估真实的分类误差。

(b) 计算困难：\textbf{密度函数 $f_g$ 通常不允许明确计算 $\hat \epsilon_{th}$}。这意味着，在许多情况下，无法通过分析确定理论误差，从而限制了准确估计分类误差的能力。

总之，摘录解释了如何利用各组的条件概率密度来模拟理论误差，但指出由于假设模型的原因，这种估计方法可能存在偏差，而且由于密度函数的复杂性，在实践中可能难以计算。这是概率判别分析中常见的难题。

\color{black}

En probabiliste , les erreur de group G sont modélisés par la fonction de probabilité f_g( *;\theta_g) est on note $T_ig$ le poids de la classe g 

\hrulefill 

#### Excercice 1 TD3 :
\footnote{Rappelle : Loi normale $f(x) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x - \mu)^2}{2\sigma^2}}$} 

On envisager deux modèle : le classifier Gaussien Hétéroscédastique $(\hat \sigma^2 _1 ≠ \hat \sigma ^2_2)$

Affectation de M. Li (découvert = 1.9)

Poid de classe: $\hat \pi_1 = \hat \pi_2 = 0.5$

Centre de classe: $\hat \mu_1 = 1,5$ et $\hat \mu_2 = 2,5$

Variance: $\hat \sigma_1^2  = 3$ et $\hat \sigma_2 ^2 = 3,2$

x = décoissant

y = classe

\textbf{两组分布表达式：}

$$
(x|y=1)\sim f(x; \hat \mu_1, \hat \sigma_1^2) = \frac{1}{\sqrt{2\pi}}\frac{1}{\hat\sigma_1}\exp\Bigg(-\frac{1}{2}\Big(\frac{x-\hat \mu_1}{\hat \sigma_1 }\Big)^2\Bigg )
$$

$$
(x|y=2)\sim f(x; \hat \mu_2, \hat \sigma_2^2) = \frac{1}{\sqrt{2\pi}}\frac{1}{\hat\sigma_2}\exp\Bigg(-\frac{1}{2}\Big(\frac{x-\hat \mu_2}{\hat \sigma_2 }\Big)^2\Bigg )
$$
\textbf{概率表达式：}

$$
P(Li \in Class 1 | x(Li) = 1,9) = \frac {\hat \Pi_1 f_1 (1,9;\hat  \mu;\hat \sigma_1^2)}{\sum^2_{j=1}\hat\Pi_j f(1,9;\hat  \mu_j,\hat \sigma_j^2)} = \frac{\text{组1}}{\text{两组}}
$$

Sur R on a 

```{r}
library(stats)
pi1 = 0.5; pi2 = 0.5  
mu1 = 1.5; mu2 = 2.5  
sicar1 = 3; sicar2 = 3.2  
pf1 = pi1 * dnorm(1.9, mean = mu1, sd = sqrt(sicar1))
pf2 = pi2 * dnorm(1.9, mean = mu2, sd = sqrt(sicar2))
t1 = pf1/(pf1+pf2)
print(t1)
```

M.Li a 52% de class apportement à la classe 1, on affect à la class 1

\textbf{Estimation de l'erreur de classement : }

[](/Users/youmingma/Desktop/M2段乐瑶笔记/风险探测coring_applique_detection_risque/my_cours/Doc/3.jpeg)

On détermine la fontiere de classement $\gamma$ en réselment  <12>

$$
t1 (r) = t2(r)
$$

$$
\hat \pi_1 \times f_1 (r; \hat \mu_1, \hat \sigma_1^2) = \hat \pi_2 \times f_2  (r; \hat \mu_2, \hat \sigma_2^2)
$$

$$
\hat \pi _1 \frac{1}{\sqrt{2\pi}}\frac{1}{\hat \sigma_1}\exp \Bigg (-\frac{1}{2} \Big (\frac{\lambda-\hat \mu_1}{\sigma^2_1}\Big)\Bigg) = \hat \pi _2 \frac{1}{\sqrt{2\pi}}\frac{1}{\hat \sigma_2}\exp \Bigg (-\frac{1}{2} \Big (\frac{\lambda-\hat \mu_2}{\sigma^2_2}\Big)\Bigg) \qquad  (*)
$$

On résoudre à la mains et on résoudre avec R :

```{r}
y = function(x){
  pi1*dnorm(x,mu1,sqrt(sicar1))-pi2*dnorm(x, mu2, sqrt(sicar2))
}
out = uniroot (y, lower=1.5, upper = 2.5)
gamma = out$root
print(gamma)
```

--> r = 2.09


$$
\hat \varepsilon _{th} = \underbrace{\hat \Pi_1 \int _r ^+ \infty f(x; \hat \mu_1; \hat \sigma_1^2)dx}_{Partie_1} + \underbrace{\hat \Pi_2 \int _r ^+ \infty f(x; \hat \mu_2; \hat \sigma_2^2)dx}_{Partie_2}
$$

![](/Users/youmingma/Desktop/M2段乐瑶笔记/风险探测coring_applique_detection_risque/my_cours/Doc/4.jpeg)


$$
\begin{aligned}
\hat \varepsilon_{th} &=\hat \Pi_1 P(N|\hat \mu_1; \hat \sigma_1^2 >\gamma) +\hat \Pi_2 P(N|\hat \mu_2; \hat \sigma_2^2 >\gamma)\\
& = \hat \Pi_1\Big(1-f(\frac{\gamma - \hat \mu_1}{\hat \sigma_1})\Big)+\hat \Pi_2\Big(f(\frac{\gamma - \hat \mu_2}{\hat \sigma_2})\Big)
\end{aligned}
$$

Sur R, 
```{r}
Varpsilon = pi1 * (1-pnorm(2.03,mu1,sqrt(sicar1))) + pi2*pnorm(2.09,mu2,sqrt(sicar2))
print(Varpsilon)
```

$\hat \varepsilon = 0.3880232$

ii ) Classifier Gamma homosédastique : 
Même démarche avec 
$$
\hat \sigma_1^2 = \hat \sigma_2^2 = \hat \Pi_1 \times 3.0 + \hat \Pi_2 \times 3.2 = 3.1
$$

Affectation de M.Li : 
$$
t_1(Li) =0.51
$$

On affecté M.Li à classe 1 avec 51% de classe erreur de classement $\hat \varepsilon _{th} = 0.3882125$ et $\gamma= 2$

\hrulefill 


### Eurreur apparente (ou de resubstitution)

L'erreur apparente esst calculée par restitution : les observations de $D$ sont prises à la fois pour données d'apprentissage et données de test.

\begin{itemize}
  \item Construir estimée un classifieur sur les donné de $D$
  \item Pour chaque $i \in \{1,...,n\}$ déterminer la classe estimée de $x_i:\hat y (x_i)$
  \item Calculer l'eurreur apparente :  $$\hat \varepsilon = \#\{i;\hat y (x_i) \neq y_i\}/n$$ \footnote{这里的井号 $\#$ 表示数学符号中的计数符号，用于表示一个集合中元素的数量或计数。在这个上下文中，$\#{i;\hat y (x_i) \neq y_i}$ 表示了满足条件 $\hat y (x_i) \neq y_i$ 的数据点的数量。它计算了分类器在测试数据中错误分类的数据点数目。}
  \item $\hat \varepsilon_{ap}$ \textbf{sous estime l'erreur de classement (biais d'optimisme)}. Le biais de $\hat \varepsilon_{ap}$ est d'autant plus grand que n est petit ou que le modèle est complexe (beaucoup de paramètre).
\end{itemize}

\color{darkgray}
"Erreur apparentée"（或称重复估计误差）这个概念通常用于衡量模型在训练数据集上的性能。它的主要特点是，\textbf{它评估模型对于已经见过的数据的拟合程度，而不是对未见过的数据的泛化性能。}在训练数据集上计算的误差通常会\textbf{低估模型的真实性能}，因为模型可能会过度拟合训练数据，无法很好地泛化到新数据，特别是在数据有限或模型复杂时。

因此，"erreur apparentée" 或重复估计误差并不是一种很好的模型性能评估方法，因为它不能提供模型在未见过的数据上的表现。为了更全面地评估模型的性能，通常还需要使用交叉验证或将数据集划分为训练集和测试集，以便评估模型在未见过的数据上的泛化能力。这可以帮助确定模型是否过度拟合了训练数据，以及模型在真实世界中的实际效果如何。
\color{black}


### Boostrap

L'erreur estimée par bootstrap vise à réduire le biais de l'erreur apparente $\hat \varepsilon_{ap}$ calculée sur $D$. Pour $j=1,...,N:$

\begin{itemize}
  \item objectif : corrigé le biais de $\hat \varepsilon _ap$
  \item étapes : pour i affant de 1 à N (chemin)
  \begin{itemize}
    \item tirer de $D$ un échantillon $D_j$ de taille $n$ compoetant de possibles répétitions
    \item construire le classifieur sur les données de $D_j$ puis:(使用 $D_j$ 上的数据来构建一个分类器，然后：)
    \begin{itemize}
      \item classer les données de $D_i$ et déterminer me taix d'erreur $\hat \varepsilon_{D_j}$
      \item classer les données de $D$ et déterminer le taux d'erreur $\hat \varepsilon_{D}$
    \end{itemize}
  \end{itemize}
  \item calculer $\beta_j = \hat \varepsilon_{D_j} - \hat \varepsilon_D$
\end{itemize}

L'erreur estimée par bootstrap est : $\hat \varepsilon_{boot} = \hat \varepsilon_{ap} +\sum^N_{j=1} \beta_j /N$

Le terme $\sum^N_{j=1} \beta_j /N$ est destiné à corriger le biais d'optimisme associé à l'erreur apparente $\hat \varepsilon_{ap}$

### Leave one out

Le leave One Out ou validation croissée sonsidère tout à tout chacun des points de $D$ pour donnée de test et les autres points pour données d'apprntissage. 留一法是一种交叉验证的技巧，它考虑将每一个数据点作为测试数据，其余数据点作为训练数据。这意味着对于每个数据点 $x_i$，它都会被单独用作测试数据，其余数据点用于训练。

Pour $i = 1,...,n$ : 
\begin{itemize}
  \item construire la classifieur sur D privé de $(x_i, y_i)$  构建一个分类器，使用数据集 $D$ 但不包括数据点 $(x_i, y_i)$。
  \item estimer la classe de $x_i : y_i$  估计数据点 $x_i$ 的类别，表示为 $\hat y_i$。
  \item comparer $\hat y_i$ à la vraie classe de $x_i : y_i$  比较 $\hat y_i$ 与数据点 $x_i$ 的真实类别 $y_i$。
\end{itemize}

L'erreur de calidation croisée (Crosse Validation) est $\hat \varepsilon_{CV} = \sum^n_{i=1} 1_{\{\hat y_i \neq y_i\}/n}$

交叉验证错误率 $\hat \varepsilon_{CV}$ 是通过计算被分类器错误分类的数据点数量，然后除以数据点总数 n，得到的错误率。具体公式为：$\hat \varepsilon_{CV} = \sum^n_{i=1} 1_{{\hat y_i \neq y_i}/n}$。

\color{darkgray}
留一法交叉验证的主要思想是通过反复单独测试每个数据点，以获得对分类器性能的更准确估计。它是一种有效的方法，特别适用于小型数据集或在评估分类器性能时需要减小估计偏差的情况。

\color{black}


### v-flod Cross Validation

受留一法启发，On établit d'abord une partition de $\{1,...,n\}$ en K groupes de tailles similaires : $I_1,...,I_K$. Puis, pour $k =\{1,...,K\}$ : 

\begin{itemize}
  \item on construit un classifieur sur $\{(x_i, y_i); i \notin I_k\}$
  \item on calcue l'erreur de classement $\hat \varepsilon_k$ sur $\{(x_i,y_i); i \in I_k\}$
\end{itemize}
L'erreur v-fold Cross Validation est : $\hat \varepsilon_{v-flod\ CV} = \sum^K_{k=1} \hat \varepsilon_k /K$.

Lorsque $K= n$, le v-flod Crosse validation est un Leave One Out

\color{darkgray}
v-fold 交叉验证是一种常用的模型评估方法，它允许将数据集分成多个子集，以多次评估模型性能，从而提供更准确的性能估计。这对于在小样本情况下或需要减小估计偏差的情况下非常有用。
\color{black}



# Les courbes ROC (receier opérating characteristic)

On suppose le donné répartis en deux classes 

* Classe_1 = sans risque 

* Classe_2 = à risque 

Un indicidu $x \in X$ est affect à l'une de classe par comparaison de non score à un seuil c : 

* $\hat y(x) = 2 \quad \text{ssi} \quad s(x)>c$

* $\hat y(x) = 1 \quad \text{ssi} \quad s(x)≤c$

Les observation se répartient en quatre catégories : 

|Etat|Explication|Equation|
|:---|:----|:-------|
|Faux Positifs|真1算2|$FP = \#\{y_i=1, \hat y(x_i)=2\}$|
|Vrais Positifs|真2算2|$VP = \#\{y_i=2, \hat y(x_i)=2\}$|
|Faux Négatif|真2算1|$FN = \#\{y_i=2, \hat y(x_i)=1\}$|
|Vrais Négatif|真1算1|$VN = \#\{y_i=1, \hat y(x_i)=1\}$|

|||
|:---|:---|
|Nombre de négatif|$N = FP + VN$|
|Nombre de possitif|$P = VP+FN$|
|Taux de faux possitif|$TFP = FP/N$|
|Taux de vrais possitif|$TVP = VP/P$|

\textbf{remarque} L'erreur apparente est :
$$
\hat \varepsilon_{esp} = TFP \times \frac N n + \vert 1-TVP \vert\times \frac P n
$$
\textbf{Justification}
$$
\begin{aligned}
TFP \times \frac N n + \vert 1-TVP \vert\times \frac P n &= \frac{FP} {N} \times\frac N n + (1-\frac {VP}P)\times \frac P n\\
&=\frac{FP} n+ \frac{P-VP}P \times \frac P n\\
& = \frac {FR} n + \frac{FN}n\\
&= \frac{FP + FN}n\\
&= \frac{\# \{\text{mal classe}\}} n\\
&= \hat \varepsilon_{ap}
\end{aligned}
$$



Le statistique TFP et TVP depandent du seuil c auquel on compare les valeurs du score S calculés en l'échantillon de test 

à chaque caleur de c xxxxxxx par du couple (TFP, TVP)

Les courb ROC est l'emsemble des points {(TFPc; TVPc);c\in s(X)}

On appelle avec (area under curve) 
l'aire sous la courbe Roc


Exercice en considère les données  de table 3 EX3 td 3


Tracer la courbe ROC du classification 

![](/Users/youmingma/Desktop/M2段乐瑶笔记/风险探测coring_applique_detection_risque/my_cours/Doc/8.png)

||$\hat 1$|$\hat 2$|||
|:---:|:---:|:---:|:---:|:---:|
|1|2|4|6|TFP = 2/3|
|2|2|2|4|TVP = 1/2|

Seuille c = 1/2

![](/Users/youmingma/Desktop/M2段乐瑶笔记/风险探测coring_applique_detection_risque/my_cours/Doc/9.jpeg)

# Choix de modèle

On peut comparer les modèles paramètrique ou semi-paramétrique par des critère d'information Tel que AIC , BIC ( voir CH2) 

Cependantn un critère de choix de modèle réalise un objectif (AIC estime la déviance d'un modèle, BIC estime la probabilité d'un modèle coditionnellement aux données, etc)

L'objectif du critère de choix de modèle peut être éloigné de celui de la classification. \textbf{Autrement dit, un modèle peut être bon du moint de vie du critère qu'il optimise mais ne pas conduire à un classifieur satisfaissant.}




étape : établir une partition de {1,....,n} en K classe de 

```{r}
#x = read.table(file = "http://alexandrelourme.free.fr/M2IREF/SCORING/BANKNOTE" , sep=',', dec='.' , header = TRUE)
```
On considère trois modèle : 

* AD Gaussienne honorosédastique
* AD Gaussienne hétérosédastique
* Regression logistique 

Determiner sous classe de modèle 

- l'erreur LOO
- L'erreur apparente 
- La class de nouveau billet : Length = 214,90 Right = 129,96 Left = 130,12

$$
\hat \varepsilon _{boost} = (\frac{1}{N}\sum^N_{i=1}\beta_i)+ \hat \varepsilon_{op}
$$
> V flod cross valuation 
Pricipe : le même que $L_oe$ mesure à chaque estimation  stocastique plusieur port de donnés d'appentissage

etape : 
établir une partition de {1,...n} en t class de taille I_1,...,I_K
peu d'allant de 1 à K

cotinuer un classifier sur D1{();\in I_k}
Estimer le taux d'errer sur {(x,z); i\in I_l} : $\hat \varepsilon$

Erreur V-flod cross valuation est 
$$
\hat \varepsilon_{V-flod} = \sum^k_{k=1}\hat \varepsilon_k /k
$$

